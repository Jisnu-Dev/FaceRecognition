{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\n",
      "‚úÖ Model loaded successfully!\n",
      "‚úÖ Loaded 9 faces from database!\n",
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image file\n",
      "2Ô∏è‚É£ Capture and add a face using webcam (multiple angles)\n",
      "3Ô∏è‚É£ Search for a face in an image\n",
      "4Ô∏è‚É£ Start real-time face recognition\n",
      "5Ô∏è‚É£ Exit\n",
      "üì∑ Starting real-time face recognition. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/.pyenv/versions/3.10.16/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image file\n",
      "2Ô∏è‚É£ Capture and add a face using webcam (multiple angles)\n",
      "3Ô∏è‚É£ Search for a face in an image\n",
      "4Ô∏è‚É£ Start real-time face recognition\n",
      "5Ô∏è‚É£ Exit\n",
      "üëã Exiting...\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "import cv2\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load face analysis model\n",
    "model = insightface.app.FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
    "model.prepare(ctx_id=0, det_size=(640, 640))\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Database and FAISS index\n",
    "face_db = {}\n",
    "id_to_name = []\n",
    "embedding_dim = 512  \n",
    "index = faiss.IndexFlatIP(embedding_dim)  # FAISS Index for fast search\n",
    "db_file = \"face_db.json\"\n",
    "\n",
    "def normalize(emb):\n",
    "    \"\"\"Normalize embeddings for cosine similarity.\"\"\"\n",
    "    return emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "def detect_and_embed(img):\n",
    "    \"\"\"Detects faces in an image and extracts embeddings.\"\"\"\n",
    "    faces = model.get(img)\n",
    "    if not faces:\n",
    "        return [], None  # No faces detected\n",
    "\n",
    "    # Sort faces based on size (largest face first)\n",
    "    faces = sorted(faces, key=lambda face: (face.bbox[2] - face.bbox[0]) * (face.bbox[3] - face.bbox[1]), reverse=True)\n",
    "    \n",
    "    embeddings = np.array([face.embedding for face in faces], dtype=np.float32)\n",
    "    return faces, embeddings\n",
    "\n",
    "def add_face(name, img_path=None):\n",
    "    \"\"\"Adds all face images of a person to the database.\"\"\"\n",
    "    global face_db, index, id_to_name\n",
    "\n",
    "    person_dir = f\"Data/Images/{name}\"\n",
    "    \n",
    "    # If a specific image is provided, use it\n",
    "    if img_path:\n",
    "        img_paths = [img_path]\n",
    "    else:\n",
    "        if not os.path.exists(person_dir):\n",
    "            print(f\"‚ùå No images found for {name}!\")\n",
    "            return\n",
    "        img_paths = [os.path.join(person_dir, img) for img in os.listdir(person_dir) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ùå Error reading {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        faces, embeddings = detect_and_embed(img)\n",
    "        if embeddings is None or len(embeddings) == 0:\n",
    "            print(f\"‚ö†Ô∏è No face detected in {img_path}\")\n",
    "            continue\n",
    "\n",
    "        embeddings = normalize(embeddings)  # Normalize for FAISS\n",
    "        all_embeddings.append(embeddings[0])  # Only take the largest face\n",
    "\n",
    "    if not all_embeddings:\n",
    "        print(f\"‚ùå No valid faces added for {name}\")\n",
    "        return\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)  # Stack all embeddings together\n",
    "    \n",
    "    # Add embeddings to FAISS and store in database\n",
    "    face_db[name] = all_embeddings.tolist()\n",
    "    index.add(all_embeddings)  # Add all images to FAISS\n",
    "    id_to_name.extend([name] * all_embeddings.shape[0])  # Map each embedding to the name\n",
    "    \n",
    "    save_db()\n",
    "    print(f\"‚úÖ {name} added with {len(all_embeddings)} images!\")\n",
    "\n",
    "def capture_and_save(name):\n",
    "    \"\"\"Captures all profile images using the webcam and saves them.\"\"\"\n",
    "    angles = [\"front\", \"left\", \"right\", \"up\"]\n",
    "    os.makedirs(f\"Data/Images/{name}\", exist_ok=True)\n",
    "\n",
    "    for angle in angles:\n",
    "        input(f\"üì∏ Look {angle} and press ENTER to capture...\")\n",
    "        \n",
    "        cam = cv2.VideoCapture(\"rtsp://admin:bitsathY@192.168.1.11\")\n",
    "        if not cam.isOpened():\n",
    "            print(\"‚ùå Error: Could not open camera.\")\n",
    "            return\n",
    "\n",
    "        ret, frame = cam.read()\n",
    "        cam.release()\n",
    "        if not ret:\n",
    "            print(f\"‚ùå Error: Could not capture {angle} image.\")\n",
    "            return\n",
    "        \n",
    "        img_path = f\"Data/Images/{name}/{angle}.jpg\"\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        print(f\"‚úÖ {angle} image saved.\")\n",
    "        \n",
    "    add_face(name)  # Load all images after capturing\n",
    "\n",
    "def search_face(img):\n",
    "    \"\"\"Search for faces in an image using FAISS.\"\"\"\n",
    "    faces, test_embeddings = detect_and_embed(img)\n",
    "    if test_embeddings is None:\n",
    "        return []\n",
    "\n",
    "    norm_test_embeddings = normalize(test_embeddings)\n",
    "    D, I = index.search(norm_test_embeddings, 1)  # Search for the closest match\n",
    "\n",
    "    results = []\n",
    "    for idx, (best_match_idx, best_score) in enumerate(zip(I[:, 0], D[:, 0])):\n",
    "        if best_match_idx != -1 and best_score > 0.5:\n",
    "            matched_name = id_to_name[best_match_idx]\n",
    "        else:\n",
    "            matched_name = \"Unknown\"\n",
    "\n",
    "        results.append((faces[idx].bbox, matched_name, best_score))\n",
    "\n",
    "    return results\n",
    "\n",
    "def real_time_recognition():\n",
    "    \"\"\"Real-time face recognition using webcam.\"\"\"\n",
    "    cam = cv2.VideoCapture(\"rtsp://admin:bitsathY@192.168.1.11\")\n",
    "    if not cam.isOpened():\n",
    "        print(\"‚ùå Error: Could not open camera.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üì∑ Starting real-time face recognition. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"‚ùå Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        results = search_face(frame)\n",
    "\n",
    "        for bbox, name, score in results:\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{name} ({score:.2f})\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Real-time Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def save_db():\n",
    "    \"\"\"Save face embeddings to a JSON file for persistence.\"\"\"\n",
    "    with open(db_file, 'w') as f:\n",
    "        json.dump(face_db, f)\n",
    "    print(\"üíæ Database saved!\")\n",
    "\n",
    "def load_db():\n",
    "    \"\"\"Load face embeddings from JSON file and restore FAISS index.\"\"\"\n",
    "    global face_db, index, id_to_name\n",
    "\n",
    "    if not os.path.exists(db_file):\n",
    "        print(\"‚ö†Ô∏è No database found. Starting fresh!\")\n",
    "        return\n",
    "    \n",
    "    with open(db_file, 'r') as f:\n",
    "        face_db = json.load(f)\n",
    "\n",
    "    all_embeddings = []\n",
    "    id_to_name.clear()\n",
    "    \n",
    "    for name, embeddings in face_db.items():\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)\n",
    "        all_embeddings.append(embeddings)\n",
    "        id_to_name.extend([name] * embeddings.shape[0])\n",
    "\n",
    "    if all_embeddings:\n",
    "        index.add(np.vstack(all_embeddings))\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(face_db)} faces from database!\")\n",
    "\n",
    "def main():\n",
    "    load_db()  # Load saved embeddings at startup\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"1Ô∏è‚É£ Add a face from an image file\")\n",
    "        print(\"2Ô∏è‚É£ Capture and add a face using webcam (multiple angles)\")\n",
    "        print(\"3Ô∏è‚É£ Search for a face in an image\")\n",
    "        print(\"4Ô∏è‚É£ Start real-time face recognition\")\n",
    "        print(\"5Ô∏è‚É£ Exit\")\n",
    "        choice = input(\"Enter your choice: \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            name = input(\"Enter name: \").strip()\n",
    "            img_path = input(\"Enter image path: \").strip()\n",
    "            if os.path.exists(img_path):\n",
    "                add_face(name, img_path)\n",
    "            else:\n",
    "                print(\"‚ùå File not found!\")\n",
    "        elif choice == '2':\n",
    "            name = input(\"Enter name: \").strip()\n",
    "            capture_and_save(name)\n",
    "        elif choice == '3':\n",
    "            img_path = input(\"Enter test image path: \").strip()\n",
    "            if os.path.exists(img_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                results = search_face(img)\n",
    "                for bbox, name, score in results:\n",
    "                    print(f\"‚úÖ Matched: {name} (Similarity: {score:.2f})\")\n",
    "            else:\n",
    "                print(\"‚ùå File not found!\")\n",
    "        elif choice == '4':\n",
    "            real_time_recognition()\n",
    "        elif choice == '5':\n",
    "            print(\"üëã Exiting...\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid choice, try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    dev=\"cuda:0\"\n",
    "device=torch.device(dev)\n",
    "a=torch.zeros(4,3)\n",
    "a=a.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\n",
      "‚úÖ Model loaded successfully!\n",
      "‚úÖ Loaded 7 faces from database!\n",
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image file\n",
      "2Ô∏è‚É£ Start real-time face recognition\n",
      "3Ô∏è‚É£ Exit\n",
      "üì∑ Starting real-time face recognition. Press 'q' to quit.\n",
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image file\n",
      "2Ô∏è‚É£ Start real-time face recognition\n",
      "3Ô∏è‚É£ Exit\n",
      "‚ùå Invalid choice, try again.\n",
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image file\n",
      "2Ô∏è‚É£ Start real-time face recognition\n",
      "3Ô∏è‚É£ Exit\n",
      "üëã Exiting...\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "import cv2\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load face analysis model\n",
    "model = insightface.app.FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
    "model.prepare(ctx_id=0, det_size=(640, 640))\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Database and FAISS index\n",
    "face_db = {}\n",
    "id_to_name = []\n",
    "embedding_dim = 512  \n",
    "index = faiss.IndexFlatIP(embedding_dim)  # FAISS Index for fast search\n",
    "db_file = \"face_db.json\"\n",
    "\n",
    "def normalize(emb):\n",
    "    \"\"\"Normalize embeddings for cosine similarity.\"\"\"\n",
    "    return emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "def detect_and_embed(img):\n",
    "    \"\"\"Detects faces in an image and extracts embeddings.\"\"\"\n",
    "    faces = model.get(img)\n",
    "    if not faces:\n",
    "        return [], None  # No faces detected\n",
    "\n",
    "    # Sort faces based on size (largest face first)\n",
    "    faces = sorted(faces, key=lambda face: (face.bbox[2] - face.bbox[0]) * (face.bbox[3] - face.bbox[1]), reverse=True)\n",
    "    \n",
    "    embeddings = np.array([face.embedding for face in faces], dtype=np.float32)\n",
    "    return faces, embeddings\n",
    "\n",
    "def add_face(name, img_path=None):\n",
    "    \"\"\"Adds all face images of a person to the database.\"\"\"\n",
    "    global face_db, index, id_to_name\n",
    "\n",
    "    person_dir = f\"Data/Images/{name}\"\n",
    "    \n",
    "    # If a specific image is provided, use it\n",
    "    if img_path:\n",
    "        img_paths = [img_path]\n",
    "    else:\n",
    "        if not os.path.exists(person_dir):\n",
    "            print(f\"‚ùå No images found for {name}!\")\n",
    "            return\n",
    "        img_paths = [os.path.join(person_dir, img) for img in os.listdir(person_dir) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ùå Error reading {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        faces, embeddings = detect_and_embed(img)\n",
    "        if embeddings is None or len(embeddings) == 0:\n",
    "            print(f\"‚ö†Ô∏è No face detected in {img_path}\")\n",
    "            continue\n",
    "\n",
    "        embeddings = normalize(embeddings)  # Normalize for FAISS\n",
    "        all_embeddings.append(embeddings[0])  # Only take the largest face\n",
    "\n",
    "    if not all_embeddings:\n",
    "        print(f\"‚ùå No valid faces added for {name}\")\n",
    "        return\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)  # Stack all embeddings together\n",
    "    \n",
    "    # Add embeddings to FAISS and store in database\n",
    "    face_db[name] = all_embeddings.tolist()\n",
    "    index.add(all_embeddings)  # Add all images to FAISS\n",
    "    id_to_name.extend([name] * all_embeddings.shape[0])  # Map each embedding to the name\n",
    "    \n",
    "    save_db()\n",
    "    print(f\"‚úÖ {name} added with {len(all_embeddings)} images!\")\n",
    "\n",
    "def search_face(img):\n",
    "    \"\"\"Search for faces in an image using FAISS.\"\"\"\n",
    "    faces, test_embeddings = detect_and_embed(img)\n",
    "    if test_embeddings is None:\n",
    "        return []\n",
    "\n",
    "    norm_test_embeddings = normalize(test_embeddings)\n",
    "    D, I = index.search(norm_test_embeddings, 1)  # Search for the closest match\n",
    "\n",
    "    results = []\n",
    "    for idx, (best_match_idx, best_score) in enumerate(zip(I[:, 0], D[:, 0])):\n",
    "        if best_match_idx != -1 and best_score > 0.5:\n",
    "            matched_name = id_to_name[best_match_idx]\n",
    "        else:\n",
    "            matched_name = \"Unknown\"\n",
    "\n",
    "        results.append((faces[idx].bbox, matched_name, best_score))\n",
    "\n",
    "    return results\n",
    "\n",
    "def real_time_recognition():\n",
    "    \"\"\"Real-time face recognition using optimized RTSP handling.\"\"\"\n",
    "    rtsp_url = \"rtsp://admin:bitsathY@192.168.1.11\"\n",
    "    \n",
    "    # Use FFmpeg for better RTSP handling\n",
    "    cam = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)\n",
    "    \n",
    "    if not cam.isOpened():\n",
    "        print(\"‚ùå Error: Could not open RTSP camera.\")\n",
    "        return\n",
    "\n",
    "    cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduce buffering\n",
    "    cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Set fixed resolution\n",
    "    cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    print(\"üì∑ Starting real-time face recognition. Press 'q' to quit.\")\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"‚ö†Ô∏è Warning: Could not read frame. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 2 == 0:  # Process every 2nd frame\n",
    "            continue\n",
    "\n",
    "        results = search_face(frame)\n",
    "\n",
    "        for bbox, name, score in results:\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{name} ({score:.2f})\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Real-time Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def save_db():\n",
    "    \"\"\"Save face embeddings to a JSON file for persistence.\"\"\"\n",
    "    with open(db_file, 'w') as f:\n",
    "        json.dump(face_db, f)\n",
    "    print(\"üíæ Database saved!\")\n",
    "\n",
    "def load_db():\n",
    "    \"\"\"Load face embeddings from JSON file and restore FAISS index.\"\"\"\n",
    "    global face_db, index, id_to_name\n",
    "\n",
    "    if not os.path.exists(db_file):\n",
    "        print(\"‚ö†Ô∏è No database found. Starting fresh!\")\n",
    "        return\n",
    "    \n",
    "    with open(db_file, 'r') as f:\n",
    "        face_db = json.load(f)\n",
    "\n",
    "    all_embeddings = []\n",
    "    id_to_name.clear()\n",
    "    \n",
    "    for name, embeddings in face_db.items():\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)\n",
    "        all_embeddings.append(embeddings)\n",
    "        id_to_name.extend([name] * embeddings.shape[0])\n",
    "\n",
    "    if all_embeddings:\n",
    "        index.add(np.vstack(all_embeddings))\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(face_db)} faces from database!\")\n",
    "\n",
    "def main():\n",
    "    load_db()  # Load saved embeddings at startup\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"1Ô∏è‚É£ Add a face from an image file\")\n",
    "        print(\"2Ô∏è‚É£ Start real-time face recognition\")\n",
    "        print(\"3Ô∏è‚É£ Exit\")\n",
    "        choice = input(\"Enter your choice: \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            name = input(\"Enter name: \").strip()\n",
    "            img_path = input(\"Enter image path: \").strip()\n",
    "            if os.path.exists(img_path):\n",
    "                add_face(name, img_path)\n",
    "            else:\n",
    "                print(\"‚ùå File not found!\")\n",
    "        elif choice == '2':\n",
    "            real_time_recognition()\n",
    "        elif choice == '3':\n",
    "            print(\"üëã Exiting...\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid choice, try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/admin1/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\n",
      "‚úÖ Model loaded successfully!\n",
      "‚úÖ Loaded 9 faces from database!\n",
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image\n",
      "2Ô∏è‚É£ Capture and add a face\n",
      "3Ô∏è‚É£ Search for a face in an image\n",
      "4Ô∏è‚É£ Start real-time recognition\n",
      "5Ô∏è‚É£ Exit\n",
      "üì∑ Starting real-time face recognition. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/.pyenv/versions/3.10.16/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Options:\n",
      "1Ô∏è‚É£ Add a face from an image\n",
      "2Ô∏è‚É£ Capture and add a face\n",
      "3Ô∏è‚É£ Search for a face in an image\n",
      "4Ô∏è‚É£ Start real-time recognition\n",
      "5Ô∏è‚É£ Exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:24@3284.881] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.599082 ms\n",
      "[ WARN:24@3314.919] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.903181 ms\n",
      "[ WARN:24@3344.968] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.076131 ms\n",
      "[ WARN:24@3375.006] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.122069 ms\n",
      "[ WARN:24@3405.043] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.283130 ms\n",
      "[ WARN:24@3435.077] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.757227 ms\n",
      "[ WARN:24@3465.111] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.495151 ms\n",
      "[ WARN:24@3495.144] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30032.839996 ms\n",
      "[ WARN:24@3525.177] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.805608 ms\n",
      "[ WARN:24@3555.213] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.127224 ms\n",
      "[ WARN:24@3585.248] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.013103 ms\n",
      "[ WARN:24@3615.281] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.388901 ms\n",
      "[ WARN:24@3645.315] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.353280 ms\n",
      "[ WARN:24@3675.353] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.279478 ms\n",
      "[ WARN:24@3705.393] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30039.966276 ms\n",
      "[ WARN:24@3735.430] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.368798 ms\n",
      "[ WARN:24@3765.469] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.597515 ms\n",
      "[ WARN:24@3795.506] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.308880 ms\n",
      "[ WARN:24@3825.545] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.564940 ms\n",
      "[ WARN:24@3855.585] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30039.778302 ms\n",
      "[ WARN:24@3885.624] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30039.540031 ms\n",
      "[ WARN:24@3915.663] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.198409 ms\n",
      "[ WARN:24@3945.700] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.404950 ms\n",
      "[ WARN:24@3975.739] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.490662 ms\n",
      "[ WARN:24@4005.777] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.782538 ms\n",
      "[ WARN:24@4035.815] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.357207 ms\n",
      "[ WARN:24@4065.856] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30041.228176 ms\n",
      "[ WARN:24@4095.893] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.042455 ms\n",
      "[ WARN:24@4125.929] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.682973 ms\n",
      "[ WARN:24@4155.967] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.881408 ms\n",
      "[ WARN:24@4186.007] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30039.421871 ms\n",
      "[ WARN:24@4216.043] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.598177 ms\n",
      "[ WARN:24@4246.075] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30031.485559 ms\n",
      "[ WARN:24@4276.111] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.082445 ms\n",
      "[ WARN:24@4306.143] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30032.514393 ms\n",
      "[ WARN:24@4336.178] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.616992 ms\n",
      "[ WARN:24@4366.213] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.499488 ms\n",
      "[ WARN:24@4396.247] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.494970 ms\n",
      "[ WARN:24@4426.282] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.376230 ms\n",
      "[ WARN:24@4456.315] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.169109 ms\n",
      "[ WARN:24@4486.349] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.883796 ms\n",
      "[ WARN:24@4516.383] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.726212 ms\n",
      "[ WARN:24@4546.418] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.489569 ms\n",
      "[ WARN:24@4576.454] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.741963 ms\n",
      "[ WARN:24@4606.495] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30040.500208 ms\n",
      "[ WARN:24@4636.549] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30054.241232 ms\n",
      "[ WARN:24@4666.602] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30053.187392 ms\n",
      "[ WARN:24@4696.650] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30047.356714 ms\n",
      "[ WARN:24@4726.699] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30048.932563 ms\n",
      "[ WARN:24@4756.748] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30049.240356 ms\n",
      "[ WARN:24@4786.802] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30053.923600 ms\n",
      "[ WARN:24@4816.845] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30043.364763 ms\n",
      "[ WARN:24@4846.890] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30044.713266 ms\n",
      "[ WARN:24@4876.935] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30045.153981 ms\n",
      "[ WARN:24@4906.986] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30050.387594 ms\n",
      "[ WARN:24@4937.042] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30056.118907 ms\n",
      "[ WARN:24@4967.114] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30072.034010 ms\n",
      "[ WARN:24@4997.196] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30081.502637 ms\n",
      "[ WARN:24@5027.281] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30085.362533 ms\n",
      "[ WARN:24@5057.361] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30080.176418 ms\n",
      "[ WARN:24@5087.439] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30077.211710 ms\n",
      "[ WARN:24@5117.521] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30082.595804 ms\n",
      "[ WARN:24@5147.601] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30079.394561 ms\n",
      "[ WARN:24@5177.687] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30086.303223 ms\n",
      "[ WARN:24@5207.777] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30089.368096 ms\n",
      "[ WARN:24@5237.857] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30080.557569 ms\n",
      "[ WARN:24@5267.936] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30078.071130 ms\n",
      "[ WARN:24@5298.017] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30081.519800 ms\n",
      "[ WARN:24@5328.090] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30072.852995 ms\n",
      "[ WARN:24@5358.178] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30088.304943 ms\n",
      "[ WARN:24@5388.259] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30080.358859 ms\n",
      "[ WARN:24@5418.345] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30085.697249 ms\n",
      "[ WARN:24@5448.426] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30081.406288 ms\n",
      "[ WARN:24@5478.510] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30084.036463 ms\n",
      "[ WARN:24@5508.593] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30083.052342 ms\n",
      "[ WARN:24@5538.680] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30086.708256 ms\n",
      "[ WARN:24@5568.748] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30067.633041 ms\n",
      "[ WARN:24@5598.829] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30081.244167 ms\n",
      "[ WARN:24@5628.914] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30084.753143 ms\n",
      "[ WARN:24@5658.995] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30080.851333 ms\n",
      "[ WARN:24@5689.068] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30073.394708 ms\n",
      "[ WARN:24@5719.147] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30079.243346 ms\n",
      "[ WARN:24@5749.227] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30079.083489 ms\n",
      "[ WARN:24@5779.303] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30076.789284 ms\n",
      "[ WARN:24@5809.379] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30075.659469 ms\n",
      "[ WARN:24@5839.464] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30084.454259 ms\n",
      "[ WARN:24@5869.547] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30082.533061 ms\n",
      "[ WARN:24@5899.621] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30074.720094 ms\n",
      "[ WARN:24@5929.692] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30071.046275 ms\n",
      "[ WARN:24@5959.770] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30077.544300 ms\n",
      "[ WARN:24@5989.845] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30074.500669 ms\n",
      "[ WARN:24@6019.915] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30070.759857 ms\n",
      "[ WARN:24@6049.995] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30079.163791 ms\n",
      "[ WARN:24@6080.068] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30073.739499 ms\n",
      "[ WARN:24@6110.143] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30074.070155 ms\n",
      "[ WARN:24@6140.223] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30080.827020 ms\n",
      "[ WARN:24@6170.300] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30076.663822 ms\n",
      "[ WARN:24@6200.378] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30077.184046 ms\n",
      "[ WARN:24@6230.447] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30069.630270 ms\n",
      "[ WARN:24@6260.493] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30045.528875 ms\n",
      "[ WARN:24@6290.537] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30043.912122 ms\n",
      "[ WARN:24@6320.583] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30045.708383 ms\n",
      "[ WARN:24@6350.628] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30045.197949 ms\n",
      "[ WARN:24@6380.673] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30044.879893 ms\n",
      "[ WARN:24@6410.714] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30041.553449 ms\n",
      "[ WARN:24@6440.758] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30043.466195 ms\n",
      "[ WARN:24@6470.801] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30043.310955 ms\n",
      "[ WARN:24@6500.836] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.844712 ms\n",
      "[ WARN:24@6530.882] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30045.195357 ms\n",
      "[ WARN:24@6560.927] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30044.989524 ms\n",
      "[ WARN:24@6590.966] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30039.656078 ms\n",
      "[ WARN:24@6621.005] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.869570 ms\n",
      "[ WARN:24@6651.042] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.885487 ms\n",
      "[ WARN:24@6681.077] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.949395 ms\n",
      "[ WARN:24@6711.115] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.409254 ms\n",
      "[ WARN:24@6741.151] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.309113 ms\n",
      "[ WARN:24@6771.190] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.611447 ms\n",
      "[ WARN:24@6801.226] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.846112 ms\n",
      "[ WARN:24@6831.262] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.252597 ms\n",
      "[ WARN:24@6861.298] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.396477 ms\n",
      "[ WARN:24@6891.335] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.261393 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:24@6921.370] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.251496 ms\n",
      "[ WARN:24@6951.406] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.752710 ms\n",
      "[ WARN:24@6981.442] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.360238 ms\n",
      "[ WARN:24@7011.481] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.887739 ms\n",
      "[ WARN:24@7041.521] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30040.083540 ms\n",
      "[ WARN:24@7071.558] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.942684 ms\n",
      "[ WARN:24@7101.595] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.638259 ms\n",
      "[ WARN:24@7131.629] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30033.603911 ms\n",
      "[ WARN:24@7161.664] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.714981 ms\n",
      "[ WARN:24@7191.700] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.503041 ms\n",
      "[ WARN:24@7221.736] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.107459 ms\n",
      "[ WARN:24@7251.773] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.107121 ms\n",
      "[ WARN:24@7281.808] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30034.643033 ms\n",
      "[ WARN:24@7311.843] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30035.331168 ms\n",
      "[ WARN:24@7341.880] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30036.966766 ms\n",
      "[ WARN:24@7371.919] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30038.573219 ms\n",
      "[ WARN:24@7401.957] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 30037.702850 ms\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "import cv2\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# Load face analysis model\n",
    "model = insightface.app.FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
    "model.prepare(ctx_id=0, det_size=(640, 640))\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Database & FAISS index\n",
    "face_db = {}\n",
    "id_to_name = []\n",
    "embedding_dim = 512  \n",
    "index = faiss.IndexFlatIP(embedding_dim)  # FAISS Index for fast search\n",
    "db_file = \"face_db.json\"\n",
    "faiss_index_file = \"faiss_index.bin\"\n",
    "\n",
    "# RTSP Camera Setup\n",
    "RTSP_URL = \"rtsp://admin:bitsathY@192.168.1.11\"\n",
    "\n",
    "def normalize(emb):\n",
    "    \"\"\"Normalize embeddings for cosine similarity.\"\"\"\n",
    "    return emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "def detect_and_embed(img):\n",
    "    \"\"\"Detects faces in an image and extracts embeddings.\"\"\"\n",
    "    faces = model.get(img)\n",
    "    if not faces:\n",
    "        return [], None  # No faces detected\n",
    "\n",
    "    faces = sorted(faces, key=lambda face: (face.bbox[2] - face.bbox[0]) * (face.bbox[3] - face.bbox[1]), reverse=True)\n",
    "    embeddings = np.array([face.embedding for face in faces], dtype=np.float32)\n",
    "    return faces, normalize(embeddings)\n",
    "\n",
    "def add_face(name, img_path=None):\n",
    "    \"\"\"Adds all face images of a person to the database.\"\"\"\n",
    "    global face_db, index, id_to_name\n",
    "\n",
    "    person_dir = f\"Data/Images/{name}\"\n",
    "    \n",
    "    if img_path:\n",
    "        img_paths = [img_path]\n",
    "    else:\n",
    "        if not os.path.exists(person_dir):\n",
    "            print(f\"‚ùå No images found for {name}!\")\n",
    "            return\n",
    "        img_paths = [os.path.join(person_dir, img) for img in os.listdir(person_dir) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ùå Error reading {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        faces, embeddings = detect_and_embed(img)\n",
    "        if embeddings is None or len(embeddings) == 0:\n",
    "            print(f\"‚ö†Ô∏è No face detected in {img_path}\")\n",
    "            continue\n",
    "\n",
    "        all_embeddings.append(embeddings[0])  # Take the largest face\n",
    "\n",
    "    if not all_embeddings:\n",
    "        print(f\"‚ùå No valid faces added for {name}\")\n",
    "        return\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    \n",
    "    # Add embeddings to FAISS and store in database\n",
    "    face_db[name] = all_embeddings.tolist()\n",
    "    index.add(all_embeddings)\n",
    "    id_to_name.extend([name] * all_embeddings.shape[0])\n",
    "    \n",
    "    save_db()\n",
    "    print(f\"‚úÖ {name} added with {len(all_embeddings)} images!\")\n",
    "\n",
    "def capture_and_save(name):\n",
    "    \"\"\"Captures all profile images using the webcam and saves them.\"\"\"\n",
    "    angles = [\"front\", \"left\", \"right\", \"up\"]\n",
    "    os.makedirs(f\"Data/Images/{name}\", exist_ok=True)\n",
    "\n",
    "    for angle in angles:\n",
    "        input(f\"üì∏ Look {angle} and press ENTER to capture...\")\n",
    "        \n",
    "        cam = cv2.VideoCapture(RTSP_URL)\n",
    "        if not cam.isOpened():\n",
    "            print(\"‚ùå Error: Could not open camera.\")\n",
    "            return\n",
    "\n",
    "        ret, frame = cam.read()\n",
    "        cam.release()\n",
    "        if not ret:\n",
    "            print(f\"‚ùå Error: Could not capture {angle} image.\")\n",
    "            return\n",
    "        \n",
    "        img_path = f\"Data/Images/{name}/{angle}.jpg\"\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        print(f\"‚úÖ {angle} image saved.\")\n",
    "        \n",
    "    add_face(name)\n",
    "\n",
    "def search_face(img):\n",
    "    \"\"\"Search for faces in an image using FAISS.\"\"\"\n",
    "    faces, test_embeddings = detect_and_embed(img)\n",
    "    if test_embeddings is None:\n",
    "        return []\n",
    "\n",
    "    if index.ntotal == 0:  # Prevent FAISS search on empty index\n",
    "        print(\"‚ö†Ô∏è FAISS Index is empty. Add faces first!\")\n",
    "        return []\n",
    "\n",
    "    D, I = index.search(test_embeddings, 1)\n",
    "\n",
    "    results = []\n",
    "    for idx, (best_match_idx, best_score) in enumerate(zip(I[:, 0], D[:, 0])):\n",
    "        matched_name = \"Unknown\"\n",
    "        if best_match_idx != -1 and best_match_idx < len(id_to_name) and best_score > 0.5:\n",
    "            matched_name = id_to_name[best_match_idx]\n",
    "\n",
    "        results.append((faces[idx].bbox, matched_name, best_score))\n",
    "\n",
    "    return results\n",
    "\n",
    "def rtsp_camera_thread(frame_queue):\n",
    "    \"\"\"Threaded RTSP camera capture to prevent lag.\"\"\"\n",
    "    cam = cv2.VideoCapture(RTSP_URL)\n",
    "    if not cam.isOpened():\n",
    "        print(\"‚ùå Error: Could not open RTSP stream.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        if not frame_queue.full():\n",
    "            frame_queue.put(frame)\n",
    "\n",
    "def real_time_recognition():\n",
    "    \"\"\"Real-time face recognition using RTSP camera with threading.\"\"\"\n",
    "    frame_queue = queue.Queue(maxsize=1)\n",
    "    threading.Thread(target=rtsp_camera_thread, args=(frame_queue,), daemon=True).start()\n",
    "\n",
    "    print(\"üì∑ Starting real-time face recognition. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "\n",
    "            results = search_face(frame)\n",
    "\n",
    "            for bbox, name, score in results:\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "                \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{name} ({score:.2f})\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            cv2.imshow(\"Real-time Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def save_db():\n",
    "    \"\"\"Save face embeddings to JSON and FAISS index.\"\"\"\n",
    "    with open(db_file, 'w') as f:\n",
    "        json.dump(face_db, f)\n",
    "    faiss.write_index(index, faiss_index_file)\n",
    "    print(\"üíæ Database saved!\")\n",
    "\n",
    "def load_db():\n",
    "    \"\"\"Load face embeddings from JSON and restore FAISS index.\"\"\"\n",
    "    global face_db, index, id_to_name\n",
    "\n",
    "    if os.path.exists(db_file):\n",
    "        with open(db_file, 'r') as f:\n",
    "            face_db = json.load(f)\n",
    "\n",
    "    if os.path.exists(faiss_index_file):\n",
    "        index = faiss.read_index(faiss_index_file)\n",
    "\n",
    "    all_embeddings = []\n",
    "    id_to_name.clear()\n",
    "    \n",
    "    for name, embeddings in face_db.items():\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)\n",
    "        all_embeddings.append(embeddings)\n",
    "        id_to_name.extend([name] * embeddings.shape[0])\n",
    "\n",
    "    if all_embeddings:\n",
    "        index.add(np.vstack(all_embeddings))\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(face_db)} faces from database!\")\n",
    "\n",
    "def main():\n",
    "    load_db()\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"1Ô∏è‚É£ Add a face from an image\")\n",
    "        print(\"2Ô∏è‚É£ Capture and add a face\")\n",
    "        print(\"3Ô∏è‚É£ Search for a face in an image\")\n",
    "        print(\"4Ô∏è‚É£ Start real-time recognition\")\n",
    "        print(\"5Ô∏è‚É£ Exit\")\n",
    "        choice = input(\"Enter your choice: \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            name = input(\"Enter name: \").strip()\n",
    "            img_path = input(\"Enter image path: \").strip()\n",
    "            add_face(name, img_path)\n",
    "        elif choice == '2':\n",
    "            capture_and_save(input(\"Enter name: \").strip())\n",
    "        elif choice == '3':\n",
    "            img = cv2.imread(input(\"Enter image path: \").strip())\n",
    "            print(search_face(img))\n",
    "        elif choice == '4':\n",
    "            real_time_recognition()\n",
    "        elif choice == '5':\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
